# Environment
ENV_NAME = "CartPole-v1"
NO_OP_MAX_STEPS = 0
ACTION_REPETITIONS = 1
FRAMES_STACKED = 4

# Logging
LOG_DIR = "logs"
EPISODES_PATIENCE = 100

# Q-Learning
N_STEP_RETURNS = 3
GAMMA = 0.99
ACTION_SPACE_SIZE = 2
TARGET_UPDATE = 10
DOUBLE_Q_LEARNING = True

# Data generation
NUM_EPISODES = 1000000
MIN_START_STEPS = 1000
EPS_START = 1
EPS_END = 0.1
EPS_DECAY = 5000

# Replay buffer
REPLAY_BUFFER_LEN = 10000
ALPHA = 0.75
BETA0 = 0.4
REPLAY_DELAY = 300

# Training hyperparams
BATCH_SIZE = 32
CLIP_GRAD = 1
LEARNING_RATE = 0.0001

# Network architecture
NETWORK_NAME = "Dueling DQN"
INPUT_SIZE = 40
NUM_FC_HIDDEN_UNITS = 128

# Noisy Nets
NOISY_NETS = True
NOISY_SIGMA_INIT = 0.5
NUM_ATOMS = 51
V_MIN = 0
V_MAX = 50
