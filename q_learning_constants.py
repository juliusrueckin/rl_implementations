# Environment
ENV_NAME = "CartPole-v1"
INPUT_SIZE = 40
NO_OP_MAX_STEPS = 0
ACTION_REPETITIONS = 1
FRAMES_STACKED = 4

# Logging
LOG_DIR = "logs"
EPISODES_PATIENCE = 128
EVAL_FREQUENCY = 500
EVAL_EPISODE_COUNT = 10

# Q-Learning
N_STEP_RETURNS = 3
GAMMA = 0.99
TARGET_UPDATE = 1000
DOUBLE_Q_LEARNING = True

# Data generation
NUM_EPISODES = int(1e6)
MIN_START_STEPS = 5000
EPS_START = 1
EPS_END = 0.1
EPS_DECAY = 1e5

# Replay buffer
REPLAY_BUFFER_LEN = int(1e5)
ALPHA = 0.75
BETA0 = 0.4
REPLAY_DELAY = 300

# Training hyperparams
BATCH_SIZE = 32
CLIP_GRAD = 1
LEARNING_RATE = 0.0001

# Network architecture
NETWORK_NAME = "Dueling DQN"
NUM_FC_HIDDEN_UNITS = 128
NUM_CHANNELS = 64

# Noisy Nets
NOISY_NETS = True
NOISY_SIGMA_INIT = 0.5
NUM_ATOMS = 51
V_MIN = 0
V_MAX = 50
